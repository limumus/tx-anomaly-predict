import os
import json
from typing import List
import requests
from tqdm import tqdm
from langchain.embeddings.base import Embeddings
from langchain_chroma import Chroma
from langchain.schema import Document
from collections import deque

CONFIG = {
    "JSON_FOLDER_PATH": "output_de",
    "PERSIST_DIR": "vector_store_realtime_0",
    "INTERMEDIATE_FOLDER": "intermediate_data",  # æ–°å¢ä¿å­˜ä¸­é—´æ•°æ®çš„æ–‡ä»¶å¤¹
    # "JINA_API_KEY": "jina_2788715e24ec409ab14302244c6f339cjoAe0RecO8q8PHxT2_N50r_Ejo07",
    # "JINA_API_KEY": "jina_1c8147b1e3944c83afa2cf111515f7dchVtlSwkYb8mv-Y2suRmJxuo_YeMR",
    "JINA_API_KEY": "jina_23283d82eae7486a884ece2bcbaf3ecbrOg1kDYNc7qCkqbkofZ81kDjikie",
    "EMBEDDING_MODEL": "jina-embeddings-v3",
}


class RealtimeVectorStore:
    """æ”¯æŒå®æ—¶ä¿å­˜çš„å‘é‡æ•°æ®åº“ç®¡ç†ç±»"""

    def __init__(self, persist_dir: str, embedding: Embeddings, progress_file="vector_store_progress.json"):
        # åˆå§‹åŒ–ç©ºæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
        self.store = Chroma(
            persist_directory=persist_dir,
            embedding_function=embedding,
            collection_metadata={"hnsw:space": "cosine"}
        )
        self.batch_size = 5
        self.current_batch = []
        self.progress_file = progress_file
        self.processed_documents = self.load_progress()

    def load_progress(self):
        if os.path.exists(self.progress_file):
            with open(self.progress_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return []

    def save_progress(self):
        with open(self.progress_file, "w", encoding="utf-8") as f:
            json.dump(self.processed_documents, f, ensure_ascii=False, indent=2)

    def add_document(self, document: Document, embedding: List[float]):
        if document.metadata.get("source_file") in self.processed_documents:
            return  # è·³è¿‡å·²å¤„ç†çš„æ–‡æ¡£

        """æ·»åŠ å•ä¸ªæ–‡æ¡£å¹¶å®æ—¶ä¿å­˜"""
        try:
            # ä½¿ç”¨å…³é”®å­—ä¼ é€’å‚æ•°
            self.store.add_documents(documents=[document], embeddings=[embedding])
            self.processed_documents.append(document.metadata.get("source_file"))
            self.save_progress()  # ä¿å­˜è¿›åº¦
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ æ–‡æ¡£å¤±è´¥: {str(e)}")

    def finalize(self):
        """å¤„ç†å‰©ä½™æœªä¿å­˜çš„æ–‡æ¡£"""
        if self.current_batch:
            self._save_batch()

    def _save_batch(self):
        """æ‰¹é‡ä¿å­˜æ–‡æ¡£åˆ°æ•°æ®åº“"""
        try:
            docs, embs = zip(*self.current_batch)
            # ä½¿ç”¨å…³é”®å­—ä¼ é€’å‚æ•°
            self.store.add_documents(
                documents=list(docs),
                embeddings=list(embs)
            )
            self.current_batch = []
        except Exception as e:
            print(f"âš ï¸ æ‰¹é‡ä¿å­˜å¤±è´¥: {str(e)}")


class JinaEmbedding(Embeddings):
    """å®æ—¶åµŒå…¥æœåŠ¡"""

    def __init__(self):
        self.api_url = "https://api.jina.ai/v1/embeddings"
        self.headers = {
            "Authorization": f"Bearer {CONFIG['JINA_API_KEY']}",
            "Content-Type": "application/json"
        }

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self._get_embedding(text) for text in texts]

    def embed_query(self, text: str) -> List[float]:
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        try:
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": CONFIG["EMBEDDING_MODEL"],
                    "input": [text[:8192]]  # æˆªæ–­è¶…é•¿æ–‡æœ¬
                },
                timeout=15
            )
            response.raise_for_status()
            return response.json()['data'][0]['embedding']
        except Exception as e:
            print(f"âš ï¸ åµŒå…¥å¤±è´¥: {str(e)}")
            return []


class JSONDocumentProcessor:

    @staticmethod
    def process_calls(calls: List[dict]) -> List[dict]:
        queue = deque(calls)  # ä½¿ç”¨åŒç«¯é˜Ÿåˆ—å¤„ç†åµŒå¥—ç»“æ„
        all_slices, temp_slice = [], []

        while queue:
            node = queue.popleft()
            temp_slice.append({
                "id": node.get("id"),
                "contract": node.get("contract"),
                "function": node.get("function"),
                "depth": node.get("depth")
            })
            # å½“ä¸´æ—¶åˆ‡ç‰‡è¾¾åˆ°100æ¡æ—¶ä¿å­˜
            if len(temp_slice) >= 100:
                all_slices.append(temp_slice)
                temp_slice = []
            # å¤„ç†åµŒå¥—çš„å†…éƒ¨è°ƒç”¨
            queue.extend(node.get("internal_calls", []))
        # å¤„ç†å‰©ä½™ä¸è¶³100æ¡çš„åˆ‡ç‰‡
        if temp_slice:
            all_slices.append(temp_slice)
        return all_slices

    @staticmethod
    def load_json_data(folder_path: str, intermediate_folder: str, progress_file="processing_progress.json") -> List[
        Document]:
        file_paths = [
            os.path.join(root, file)
            for root, _, files in os.walk(folder_path)
            for file in files if file.endswith(".json")
        ]
        documents = []

        # è¯»å–è¿›åº¦æ–‡ä»¶
        if os.path.exists(progress_file):
            with open(progress_file, "r", encoding="utf-8") as f:
                processed_files = json.load(f)
        else:
            processed_files = []
        print(f"ğŸ“ å‘ç° {len(file_paths)} ä¸ªJSONæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")

        for index, file_path in enumerate(tqdm(file_paths, desc="ğŸ“ æ–‡ä»¶å¤„ç†è¿›åº¦", unit="æ–‡ä»¶")):
            # è·³è¿‡å·²ç»å¤„ç†è¿‡çš„æ–‡ä»¶
            if file_path in processed_files:
                continue
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                if not data.get("calls"):  # å¦‚æœæ²¡æœ‰äº¤æ˜“è°ƒç”¨æ•°æ®ï¼Œè·³è¿‡
                    continue

                calls = data.get("calls", [])
                all_slices = JSONDocumentProcessor.process_calls(calls)

                # ä¿å­˜æ¯ä¸ªæ–‡ä»¶çš„åˆ‡ç‰‡æ•°æ®åˆ°ä¸­é—´æ–‡ä»¶å¤¹
                slice_file = os.path.join(intermediate_folder, f"{os.path.basename(file_path)}_slices.json")
                with open(slice_file, "w", encoding="utf-8") as f:
                    json.dump(all_slices, f, ensure_ascii=False, indent=2)

                # å°†æ¯ä¸ªåˆ‡ç‰‡è½¬æ¢ä¸º LangChain æ–‡æ¡£
                for item in all_slices:
                    documents.append(Document(
                        page_content=json.dumps(item, ensure_ascii=False, indent=2),
                        metadata={"source_file": file_path}
                    ))
                    if all_slices:  # åªæœ‰å½“æ–‡ä»¶ç¡®å®æœ‰åˆ‡ç‰‡æ—¶æ‰æ ‡è®°ä¸ºå·²å¤„ç†
                        processed_files.append(file_path)

                        # ä¿å­˜è¿›åº¦åˆ°æ–‡ä»¶
                        with open(progress_file, "w", encoding="utf-8") as f:
                            json.dump(processed_files, f, ensure_ascii=False, indent=2)


            except Exception as e:
                print(f"âš ï¸ æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {str(e)}")

        print(f"âœ… æˆåŠŸå¤„ç† {len(documents)} ä¸ªæ–‡æ¡£")
        return documents


def main():
    # åˆå§‹åŒ–æœåŠ¡ç»„ä»¶
    embedding = JinaEmbedding()
    processor = JSONDocumentProcessor()
    vector_db = RealtimeVectorStore(CONFIG["PERSIST_DIR"], embedding)

    if not os.path.exists(CONFIG["INTERMEDIATE_FOLDER"]):
        os.makedirs(CONFIG["INTERMEDIATE_FOLDER"])
    # å¤„ç†æ–‡æ¡£å¹¶å°†ä¸­é—´ç»“æœä¿å­˜åˆ°æ–‡ä»¶å¤¹
    documents = processor.load_json_data(CONFIG["JSON_FOLDER_PATH"], CONFIG["INTERMEDIATE_FOLDER"])

    # å®æ—¶å¤„ç†æ–‡æ¡£æµå¹¶ç”ŸæˆåµŒå…¥
    for doc in tqdm(documents, desc="ç”ŸæˆåµŒå…¥"):
        try:
            # ç¡®ä¿ doc.page_content æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²
            if isinstance(doc.page_content, str):
                embedding_vector = embedding.embed_documents([doc.page_content])[0]
                vector_db.add_document(doc, embedding_vector)
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆæ–‡æ¡£: {doc.metadata.get('source_file', 'Unknown')}, å†…å®¹éå­—ç¬¦ä¸²")
                continue
        except Exception as e:
            print(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
            continue

    # ç¡®ä¿æœ€åä¸€æ‰¹æ•°æ®ä¿å­˜
    vector_db.finalize()
    print(f"âœ… å¤„ç†å®Œæˆ! æ€»æ–‡æ¡£æ•°: {len(documents)}")


if __name__ == "__main__":
    main()
