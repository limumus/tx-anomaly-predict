import os
from datetime import datetime
import pandas as pd
import chardet
import requests
import json

from dotenv import load_dotenv
from collections import deque
from langchain_core.documents import Document
from typing import List, Dict, Any, Optional
from tqdm import tqdm

# LangChainç›¸å…³æ¨¡å—
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_chroma import Chroma
from langchain.embeddings.base import Embeddings
from langchain_core.runnables import Runnable, RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


# ============== ç³»ç»Ÿé…ç½® ==============
CONFIG = {
    "JSON_FOLDER_PATH": "output_de",
    "PERSIST_DIR": "vector_store_realtime_0",
    "INTERMEDIATE_FOLDER": "intermediate_data",  # æ–°å¢ä¿å­˜ä¸­é—´æ•°æ®çš„æ–‡ä»¶å¤¹
    "CSV_PATH": "extracted_data2.csv",

    "HTTP_PROXY": "http://127.0.0.1:65151",
    "HTTPS_PROXY": "http://127.0.0.1:65151",

    "JINA_API_KEY": "jina_a60e90b9537440739995b0bfae0b8468xf3mIgPUeB2TCH9Ahnyu1NjbQ9sL",
    "EMBEDDING_MODEL": "jina-embeddings-v3",
}

# ============== ç™¾åº¦æ–‡å¿ƒERNIEæ¨¡å‹å°è£… ==============
class BaiduErnieAI:
    def __init__(self):
        self.access_key = CONFIG["BAIDU_ACCESS_KEY"]
        self.secret_key = CONFIG["BAIDU_SECRET_KEY"]
        self.api_url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie-speed-128k"

    def get_access_token(self):
        url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={self.access_key}&client_secret={self.secret_key}"
        response = requests.post(url, headers={'Content-Type': 'application/json'})
        return response.json().get("access_token")

    def generate_response(self, messages: List[Dict[str, str]]) -> str:
        """ä¿®æ­£åçš„APIè°ƒç”¨æ–¹æ³•ï¼Œåªæ¥å—æ¶ˆæ¯åˆ—è¡¨"""
        try:
            access_token = self.get_access_token()
            url = f"{self.api_url}?access_token={access_token}"

            payload = json.dumps({"messages": messages})
            response = requests.post(url,
                                     headers={'Content-Type': 'application/json'},
                                     data=payload)
            response_data = response.json()

            if "error_code" in response_data:
                print(f"APIé”™è¯¯: {response_data.get('error_msg')}")
                return f"APIé”™è¯¯: {response_data.get('error_msg')}"
            return response_data.get("result", "æœªèƒ½è·å–å›ç­”")

        except Exception as e:
            print(f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return "APIè°ƒç”¨å¼‚å¸¸"

    def simple_query(self, query: str, context: str = None) -> str:
        """æ–°å¢çš„ç®€åŒ–æŸ¥è¯¢æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•"""
        messages = []
        if context:
            messages.append({"role": "user", "content": context})
        messages.append({"role": "user", "content": query})
        return self.generate_response(messages)

# ============== åµŒå…¥æœåŠ¡å°è£… ==============
class JinaEmbedding(Embeddings):
    """å®æ—¶åµŒå…¥æœåŠ¡"""

    def __init__(self):
        self.api_url = "https://api.jina.ai/v1/embeddings"
        self.headers = {
            "Authorization": f"Bearer {CONFIG['JINA_API_KEY']}",
            "Content-Type": "application/json"
        }

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self._get_embedding(text) for text in texts]

    def embed_query(self, text: str) -> List[float]:
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        try:
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": CONFIG["EMBEDDING_MODEL"],
                    "input": [text[:8192]]  # æˆªæ–­è¶…é•¿æ–‡æœ¬
                },
                timeout=15
            )
            response.raise_for_status()
            return response.json()['data'][0]['embedding']
        except Exception as e:
            print(f"âš ï¸ åµŒå…¥å¤±è´¥: {str(e)}")
            return []


# ============== ERNIEæ¨¡å‹åŒ…è£…å™¨ ==============
class ErnieLLMWrapper(Runnable):
    """å…¼å®¹LangChain Runnableæ¥å£çš„ERNIEæ¨¡å‹åŒ…è£…å™¨"""

    def __init__(self, ernie_ai: BaiduErnieAI):
        super().__init__()
        self.ernie_ai = ernie_ai

    def invoke(self, input_data: Any, config: Optional[Dict] = None) -> AIMessage:
        """å¤„ç†å•æ¬¡è°ƒç”¨ï¼Œå…¼å®¹å¤šç§è¾“å…¥ç±»å‹"""
        try:
            # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
            if isinstance(input_data, dict):
                # å­—å…¸è¾“å…¥
                query = input_data.get("input", "")
                reference = input_data.get("reference_text", "")
            elif hasattr(input_data, "messages"):
                # ChatPromptValueè¾“å…¥
                messages = input_data.messages
                query = next((msg.content for msg in messages if isinstance(msg, HumanMessage)), "")
                reference = next((msg.content for msg in messages if isinstance(msg, SystemMessage)), "")
            else:
                return AIMessage(content="æ— æ•ˆçš„è¾“å…¥æ ¼å¼")

            # æ„å»ºERNIE APIéœ€è¦çš„æ¶ˆæ¯æ ¼å¼
            messages = []
            if reference:
                messages.append({"role": "user", "content": f"å‚è€ƒå†…å®¹: {reference[:1000]}"})
            messages.append({"role": "user", "content": query})

            # è°ƒç”¨ERNIE API
            response = self.ernie_ai.generate_response(messages)
            return AIMessage(content=response)

        except Exception as e:
            print(f"è°ƒç”¨ERNIE APIå‡ºé”™: {str(e)}")
            return AIMessage(content=f"å¤„ç†é”™è¯¯: {str(e)}")

    async def ainvoke(self, input_data: Any, config: Optional[Dict] = None) -> AIMessage:
        """å¼‚æ­¥è°ƒç”¨"""
        return self.invoke(input_data, config)

    def stream(self, input_data: Any, config: Optional[Dict] = None):
        """æµå¼å¤„ç†"""
        result = self.invoke(input_data, config)
        yield result

    async def astream(self, input_data: Any, config: Optional[Dict] = None):
        """å¼‚æ­¥æµå¼å¤„ç†"""
        async for chunk in self.stream(input_data, config):
            yield chunk


# ============== å‘é‡æ•°æ®åº“ç®¡ç† ==============
def load_or_create_vector_store(persist_dir: str, embedding: Embeddings) -> Chroma:
    """åŠ è½½æˆ–åˆ›å»ºå‘é‡æ•°æ®åº“"""
    if os.path.exists(persist_dir):
        print(f"ğŸ” åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“: {persist_dir}")
        return Chroma(persist_directory=persist_dir, embedding_function=embedding)
    else:
        print(f"ğŸ†• åˆ›å»ºæ–°å‘é‡æ•°æ®åº“: {persist_dir}")
        return Chroma(persist_directory=persist_dir, embedding_function=embedding)


def create_conversational_chain(vector_store: Chroma, llm: Runnable, csv_file_path: str) -> Runnable:
    csv_data = pd.read_csv(csv_file_path, usecols=['id', 'original_code', 'description'], encoding="MacRoman")

    # Step 1: Prompt è®¾è®¡
    contextualize_q_prompt = ChatPromptTemplate.from_messages([
        ("human", """Refine the following question based on the reference text:
        Reference Text: {reference_text}
        Original Question: {input}
        Optimized Question:
        - Ensure the refined question focuses on function call sequences, not specific function names.
        - Emphasize contract interactions and attack logic.
        """)
    ])

    qa_prompt = ChatPromptTemplate.from_messages([
        ("human", """You are an expert in analyzing smart contract attack patterns. Based on the following information, assess whether the current transaction exhibits malicious contract behavior:

        1. Current transaction behavior (system_input): This is the function call flow of the contract transaction.
        {system_input}

        2. Historical attack transaction examples (context):
        {context}

        3. Background details of the matching transactions (reference_text):
        {reference_text}

        Key Analysis Directions:
        - Context provides past examples of contract attacksâ€”all of them involved malicious behavior.
        - Your task is not to simply match context, but to critically analyze system_input.
        - Examine the function call flow, contract interactions, and fund movements to determine anomalies.
        - Ignore function names like testExploitâ€”focus solely on the logical execution flow.

        Question (query):
        {query}

        Strict Answering Rules:
        - Clearly state whether system_input represents an attack contract.
        - Provide logical reasoning for your classification (matched or unmatched).
        - If the information is insufficient, explicitly state "Uncertain."
        """)
    ])

    retriever = vector_store.as_retriever(search_kwargs={"k": 1})

    # Step 2: Retriever æ”¹é€ ï¼ŒåŠ ä¸Š CSV reference_text
    def enhanced_retriever(input_data: Dict) -> List[Document]:
        docs = retriever.invoke(input_data["input"])
        print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(docs)}")
        #print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹: {[doc.page_content[:200] for doc in docs]}")

        # å°†æ¯ä¸ªæ–‡æ¡£çš„å†…å®¹è§£æä¸º JSON
        doc_ids = []
        for doc in docs:
            try:
                json_data = json.loads(doc.page_content)  # å‡è®¾ doc.page_content æ˜¯ JSON å­—ç¬¦ä¸²
                doc_ids.extend([item['id'] for item in json_data])  # ä½¿ç”¨ extend æ¥æ·»åŠ å¤šä¸ª id
            except json.JSONDecodeError as e:
                print(f"æ— æ³•è§£ææ–‡æ¡£å†…å®¹ä¸º JSON: {doc.page_content[:100]}... é”™è¯¯: {e}")

        print(f"doc_ids: {doc_ids}")  # æ‰“å° doc_idsï¼Œç¡®ä¿æ˜¯ä¸€ä¸ªåˆ—è¡¨

        # åŒ¹é… CSV ä¸­çš„è¡Œ
        csv_data["id"] = csv_data["id"].astype(str)  # å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        matched_rows = csv_data[csv_data["id"].isin(doc_ids)]

        reference_texts = []
        for _, row in matched_rows.iterrows():
            ref_text = (
                f"ID: {row['id']}\n"
                f"original_code: {row['original_code']}\n"
                f"description: {row['description']}\n"
                "------"
            )
            reference_texts.append(ref_text)

        reference_text = "\n\n".join(reference_texts)
        #print("åŒ¹é…çš„ reference_text:", reference_text)  # è¾“å‡ºå‚è€ƒæ–‡æœ¬

        # å°†åŒ¹é…åˆ°çš„ reference_text æ·»åŠ åˆ°æ–‡æ¡£å…ƒæ•°æ®ä¸­
        for doc in docs:
            doc.metadata["reference_text"] = reference_text

        return docs

    # Step 3: å°†å†å²è¾“å…¥èå…¥å‘é‡æ£€ç´¢å™¨
    history_aware_retriever = create_history_aware_retriever(
        llm,
        RunnableLambda(lambda x: {"input": x}) | enhanced_retriever,
        contextualize_q_prompt
    )

    # Step 4: æ„é€  Prompt è¾“å…¥å­—æ®µ
    def format_inputs(inputs: Dict) -> Dict:
        # å°† Document å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        def document_to_dict(doc):
            return {
                "metadata": doc.metadata,
                "content": doc.page_content
            }

        # å¤„ç† inputs ä¸­çš„æ–‡æ¡£
        if isinstance(inputs, dict):
            for key, value in inputs.items():
                if isinstance(value, list):
                    inputs[key] = [document_to_dict(doc) if isinstance(doc, Document) else doc for doc in value]
                elif isinstance(value, Document):
                    inputs[key] = document_to_dict(value)

        # print("è¾“å…¥çš„æ•°æ®:", json.dumps(inputs, indent=2, ensure_ascii=False))  # æ‰“å°å¤„ç†åçš„ inputs


        context_docs = inputs.get("context", [])
        reference_from_csv = ""
        attack_cases_text = []

        for doc in context_docs:
            # å¦‚æœ doc æ˜¯å­—å…¸ç±»å‹ï¼Œç›´æ¥æ£€æŸ¥ "metadata" é”®
            if isinstance(doc, dict) and "metadata" in doc:
                if "reference_text" in doc["metadata"]:
                    reference_from_csv = doc["metadata"]["reference_text"]
                    attack_cases_text.append(doc["content"])

        full_query = {
            "query": inputs.get("input", ""),
            "system_input": inputs.get("system_input", ""),
            "context": "\n\n".join(attack_cases_text),
            "reference_text": reference_from_csv
        }

        print("å®Œæ•´ä¼ å…¥å¤§æ¨¡å‹çš„æŸ¥è¯¢:", json.dumps(full_query, indent=2, ensure_ascii=False))
        return full_query


    # Step 5: æ„é€ æœ€ç»ˆ QA Chain
    question_answer_chain = (
        RunnablePassthrough.assign(context=history_aware_retriever) |
        RunnableLambda(format_inputs) |
        qa_prompt |
        llm
    )

    return create_retrieval_chain(history_aware_retriever, question_answer_chain)


class ResultSaver:
    def __init__(self, output_dir: str = "results"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def save_result(self, query: str, result: dict, source_file: str):
        print("å®Œæ•´ç»“æœç»“æ„:", json.dumps(result, indent=2, ensure_ascii=False))
        is_valid = (
            isinstance(result, dict) and
            result.get("answer") and
            not result["answer"].startswith(("æœªèƒ½è·å–", "APIè°ƒç”¨å¼‚å¸¸"))
        )

        if is_valid:
            filename = os.path.join(
                self.output_dir,
                f"result_{os.path.basename(source_file)}"
            )
            data = {
                "query": query,
                "answer": result["answer"],
                "source": source_file,
                "context": [
                    {
                        "content": doc.page_content[:200] + "...",
                        "source": doc.metadata.get("source_file", "unknown")
                    } for doc in result.get("context", [])
                ],
                "timestamp": datetime.now().isoformat()
            }
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        return False


# ============== ä¸»æ‰§è¡Œæµç¨‹ ==============
if __name__ == "__main__":
    embedding = JinaEmbedding()
    vector_store = load_or_create_vector_store(CONFIG["PERSIST_DIR"], embedding)
    ernie_ai = BaiduErnieAI()
    llm = ErnieLLMWrapper(ernie_ai)

    print("=== æœåŠ¡æ£€æŸ¥ ===")
    print(f"å‘é‡æ•°æ®åº“è®°å½•: {vector_store._collection.count()}")

    conversational_chain = create_conversational_chain(
        vector_store,
        llm,
        csv_file_path=CONFIG["CSV_PATH"]
    )

    # ç¤ºä¾‹è¾“å…¥
    query = "Please analyze the current input in the context of the preceding and following text to determine whether it pertains to attack contracts?and please answer in chinese."
    system_input_path = r"G:\safe\pythonProject\output\output\2024-12\Moonhacker_exp.sol\0xd12016b25d7aef681ade3dc3c9d1a1cc12f35b2c99953ff0e0ee23a59454c4fe.txt.json"

    def load_system_input(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.dumps(json.load(f), ensure_ascii=False)
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•è¯»å– JSON æ–‡ä»¶: {e}")
            return ""

    # åŠ è½½å¹¶å‡†å¤‡å¥½ç³»ç»Ÿè¾“å…¥ï¼ˆå½“å‰äº¤æ˜“æµï¼‰
    reference_text = load_system_input(system_input_path)

    # æ‰§è¡Œå¤§æ¨¡å‹æ¨ç†ï¼Œæ³¨æ„ context æ˜¯ç”±å‘é‡åº“æœç´¢è‡ªåŠ¨è·å¾—çš„ï¼Œæ— éœ€æ‰‹åŠ¨ä¼ å…¥
    result = conversational_chain.invoke({
        "input": query,
        "system_input": reference_text,
        "chat_history": [],
    })

    print("\n=== æŸ¥è¯¢ç»“æœ ===")
    if isinstance(result, dict) and "answer" in result:
        print(f"ç­”æ¡ˆ: {result['answer']}")
        if "context" in result:
            print("\nå‚è€ƒæ–‡æ¡£:")
            for doc in result["context"]:
                print(f"- {doc.metadata.get('source_file', 'æœªçŸ¥æ¥æº')}")
    else:
        print(f"åŸå§‹ç»“æœ: {result}")
