import os
from datetime import datetime
import pandas as pd
import chardet
import requests
import json

from dotenv import load_dotenv
from collections import deque
from langchain_core.documents import Document
from typing import List, Dict, Any, Optional
from tqdm import tqdm

# LangChainç›¸å…³æ¨¡å—
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_chroma import Chroma
from langchain.embeddings.base import Embeddings
from langchain_core.runnables import Runnable, RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


# ============== ç³»ç»Ÿé…ç½® ==============
CONFIG = {
    "JSON_FOLDER_PATH": "output_de",
    "PERSIST_DIR": "vector_store_realtime_0",
    "INTERMEDIATE_FOLDER": "intermediate_data",  # æ–°å¢ä¿å­˜ä¸­é—´æ•°æ®çš„æ–‡ä»¶å¤¹
    "CSV_PATH": "extracted_data2.csv",

    "HTTP_PROXY": "http://127.0.0.1:65151",
    "HTTPS_PROXY": "http://127.0.0.1:65151",

    "JINA_API_KEY": "jina_a60e90b9537440739995b0bfae0b8468xf3mIgPUeB2TCH9Ahnyu1NjbQ9sL",
    "EMBEDDING_MODEL": "jina-embeddings-v3",
    "BAIDU_ACCESS_KEY": "hoxYjdAGl1u5ijV9WmuSa5Ld",  # ç™¾åº¦API Access Key
    "BAIDU_SECRET_KEY": "GImapGj06l7YK13nQgYN7Fsc6p1jm1Si",  # ç™¾åº¦API Secret Key
}

# ============== ç™¾åº¦æ–‡å¿ƒERNIEæ¨¡å‹å°è£… ==============
class BaiduErnieAI:
    def __init__(self):
        self.access_key = CONFIG["BAIDU_ACCESS_KEY"]
        self.secret_key = CONFIG["BAIDU_SECRET_KEY"]
        self.api_url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie-speed-128k"

    def get_access_token(self):
        url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={self.access_key}&client_secret={self.secret_key}"
        response = requests.post(url, headers={'Content-Type': 'application/json'})
        return response.json().get("access_token")

    def generate_response(self, messages: List[Dict[str, str]]) -> str:
        """ä¿®æ­£åçš„APIè°ƒç”¨æ–¹æ³•ï¼Œåªæ¥å—æ¶ˆæ¯åˆ—è¡¨"""
        try:
            access_token = self.get_access_token()
            url = f"{self.api_url}?access_token={access_token}"

            payload = json.dumps({"messages": messages})
            response = requests.post(url,
                                     headers={'Content-Type': 'application/json'},
                                     data=payload)
            response_data = response.json()

            if "error_code" in response_data:
                print(f"APIé”™è¯¯: {response_data.get('error_msg')}")
                return f"APIé”™è¯¯: {response_data.get('error_msg')}"
            return response_data.get("result", "æœªèƒ½è·å–å›ç­”")

        except Exception as e:
            print(f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return "APIè°ƒç”¨å¼‚å¸¸"

    def simple_query(self, query: str, context: str = None) -> str:
        """æ–°å¢çš„ç®€åŒ–æŸ¥è¯¢æ–¹æ³•ï¼Œç”¨äºæµ‹è¯•"""
        messages = []
        if context:
            messages.append({"role": "user", "content": context})
        messages.append({"role": "user", "content": query})
        return self.generate_response(messages)

# ============== åµŒå…¥æœåŠ¡å°è£… ==============
class JinaEmbedding(Embeddings):
    """å®æ—¶åµŒå…¥æœåŠ¡"""

    def __init__(self):
        self.api_url = "https://api.jina.ai/v1/embeddings"
        self.headers = {
            "Authorization": f"Bearer {CONFIG['JINA_API_KEY']}",
            "Content-Type": "application/json"
        }

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self._get_embedding(text) for text in texts]

    def embed_query(self, text: str) -> List[float]:
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        try:
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json={
                    "model": CONFIG["EMBEDDING_MODEL"],
                    "input": [text[:8192]]  # æˆªæ–­è¶…é•¿æ–‡æœ¬
                },
                timeout=15
            )
            response.raise_for_status()
            return response.json()['data'][0]['embedding']
        except Exception as e:
            print(f"âš ï¸ åµŒå…¥å¤±è´¥: {str(e)}")
            return []


# ============== ERNIEæ¨¡å‹åŒ…è£…å™¨ ==============
class ErnieLLMWrapper(Runnable):
    """å…¼å®¹LangChain Runnableæ¥å£çš„ERNIEæ¨¡å‹åŒ…è£…å™¨"""

    def __init__(self, ernie_ai: BaiduErnieAI):
        super().__init__()
        self.ernie_ai = ernie_ai

    def invoke(self, input_data: Any, config: Optional[Dict] = None) -> AIMessage:
        """å¤„ç†å•æ¬¡è°ƒç”¨ï¼Œå…¼å®¹å¤šç§è¾“å…¥ç±»å‹"""
        try:
            # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
            if isinstance(input_data, dict):
                # å­—å…¸è¾“å…¥
                query = input_data.get("input", "")
                reference = input_data.get("reference_text", "")
            elif hasattr(input_data, "messages"):
                # ChatPromptValueè¾“å…¥
                messages = input_data.messages
                query = next((msg.content for msg in messages if isinstance(msg, HumanMessage)), "")
                reference = next((msg.content for msg in messages if isinstance(msg, SystemMessage)), "")
            else:
                return AIMessage(content="æ— æ•ˆçš„è¾“å…¥æ ¼å¼")

            # æ„å»ºERNIE APIéœ€è¦çš„æ¶ˆæ¯æ ¼å¼
            messages = []
            if reference:
                messages.append({"role": "user", "content": f"å‚è€ƒå†…å®¹: {reference[:1000]}"})
            messages.append({"role": "user", "content": query})

            # è°ƒç”¨ERNIE API
            response = self.ernie_ai.generate_response(messages)
            return AIMessage(content=response)

        except Exception as e:
            print(f"è°ƒç”¨ERNIE APIå‡ºé”™: {str(e)}")
            return AIMessage(content=f"å¤„ç†é”™è¯¯: {str(e)}")

    async def ainvoke(self, input_data: Any, config: Optional[Dict] = None) -> AIMessage:
        """å¼‚æ­¥è°ƒç”¨"""
        return self.invoke(input_data, config)

    def stream(self, input_data: Any, config: Optional[Dict] = None):
        """æµå¼å¤„ç†"""
        result = self.invoke(input_data, config)
        yield result

    async def astream(self, input_data: Any, config: Optional[Dict] = None):
        """å¼‚æ­¥æµå¼å¤„ç†"""
        async for chunk in self.stream(input_data, config):
            yield chunk


# ============== å‘é‡æ•°æ®åº“ç®¡ç† ==============
def load_or_create_vector_store(persist_dir: str, embedding: Embeddings) -> Chroma:
    """åŠ è½½æˆ–åˆ›å»ºå‘é‡æ•°æ®åº“"""
    if os.path.exists(persist_dir):
        print(f"ğŸ” åŠ è½½å·²æœ‰å‘é‡æ•°æ®åº“: {persist_dir}")
        return Chroma(persist_directory=persist_dir, embedding_function=embedding)
    else:
        print(f"ğŸ†• åˆ›å»ºæ–°å‘é‡æ•°æ®åº“: {persist_dir}")
        return Chroma(persist_directory=persist_dir, embedding_function=embedding)


def create_conversational_chain(vector_store: Chroma, llm: Runnable, csv_file_path: str) -> Runnable:
    csv_data = pd.read_csv(csv_file_path, usecols=['id', 'original_code', 'description'], encoding="MacRoman")

    # Step 1: Prompt è®¾è®¡
    contextualize_q_prompt = ChatPromptTemplate.from_messages([
        ("human", """Refine the following question based on the reference text:
        Reference Text: {reference_text}
        Original Question: {input}
        Optimized Question:
        - Ensure the refined question focuses on function call sequences, not specific function names.
        - Emphasize contract interactions and attack logic.
        """)
    ])

    qa_prompt = ChatPromptTemplate.from_messages([
        ("human", """You are an expert in analyzing smart contract attack patterns. Based on the following information, assess whether the current transaction exhibits malicious contract behavior:

        1. Current transaction behavior (system_input): This is the function call flow of the contract transaction.
        {system_input}

        2. Historical attack transaction examples (context):
        {context}

        3. Background details of the matching transactions (reference_text):
        {reference_text}

        Key Analysis Directions:
        - Context provides past examples of contract attacksâ€”all of them involved malicious behavior.
        - Your task is not to simply match context, but to critically analyze system_input.
        - Examine the function call flow, contract interactions, and fund movements to determine anomalies.
        - Ignore function names like testExploitâ€”focus solely on the logical execution flow.

        Question (query):
        {query}

        Strict Answering Rules:
        - Clearly state whether system_input represents an attack contract.
        - Provide logical reasoning for your classification (matched or unmatched).
        - If the information is insufficient, explicitly state "Uncertain."
        """)
    ])

    retriever = vector_store.as_retriever(search_kwargs={"k": 1})

    # Step 2: Retriever æ”¹é€ ï¼ŒåŠ ä¸Š CSV reference_text
    def enhanced_retriever(input_data: Dict) -> List[Document]:
        docs = retriever.invoke(input_data["input"])
        print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(docs)}")
        #print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹: {[doc.page_content[:200] for doc in docs]}")

        # å°†æ¯ä¸ªæ–‡æ¡£çš„å†…å®¹è§£æä¸º JSON
        doc_ids = []
        for doc in docs:
            try:
                json_data = json.loads(doc.page_content)  # å‡è®¾ doc.page_content æ˜¯ JSON å­—ç¬¦ä¸²
                doc_ids.extend([item['id'] for item in json_data])  # ä½¿ç”¨ extend æ¥æ·»åŠ å¤šä¸ª id
            except json.JSONDecodeError as e:
                print(f"æ— æ³•è§£ææ–‡æ¡£å†…å®¹ä¸º JSON: {doc.page_content[:100]}... é”™è¯¯: {e}")

        print(f"doc_ids: {doc_ids}")  # æ‰“å° doc_idsï¼Œç¡®ä¿æ˜¯ä¸€ä¸ªåˆ—è¡¨

        # åŒ¹é… CSV ä¸­çš„è¡Œ
        csv_data["id"] = csv_data["id"].astype(str)  # å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        matched_rows = csv_data[csv_data["id"].isin(doc_ids)]

        reference_texts = []
        for _, row in matched_rows.iterrows():
            ref_text = (
                f"ID: {row['id']}\n"
                f"original_code: {row['original_code']}\n"
                f"description: {row['description']}\n"
                "------"
            )
            reference_texts.append(ref_text)

        reference_text = "\n\n".join(reference_texts)
        #print("åŒ¹é…çš„ reference_text:", reference_text)  # è¾“å‡ºå‚è€ƒæ–‡æœ¬

        # å°†åŒ¹é…åˆ°çš„ reference_text æ·»åŠ åˆ°æ–‡æ¡£å…ƒæ•°æ®ä¸­
        for doc in docs:
            doc.metadata["reference_text"] = reference_text

        return docs

    # Step 3: å°†å†å²è¾“å…¥èå…¥å‘é‡æ£€ç´¢å™¨
    history_aware_retriever = create_history_aware_retriever(
        llm,
        RunnableLambda(lambda x: {"input": x}) | enhanced_retriever,
        contextualize_q_prompt
    )

    # Step 4: æ„é€  Prompt è¾“å…¥å­—æ®µ
    def format_inputs(inputs: Dict) -> Dict:
        # å°† Document å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        def document_to_dict(doc):
            return {
                "metadata": doc.metadata,
                "content": doc.page_content
            }

        # å¤„ç† inputs ä¸­çš„æ–‡æ¡£
        if isinstance(inputs, dict):
            for key, value in inputs.items():
                if isinstance(value, list):
                    inputs[key] = [document_to_dict(doc) if isinstance(doc, Document) else doc for doc in value]
                elif isinstance(value, Document):
                    inputs[key] = document_to_dict(value)

        # print("è¾“å…¥çš„æ•°æ®:", json.dumps(inputs, indent=2, ensure_ascii=False))  # æ‰“å°å¤„ç†åçš„ inputs


        context_docs = inputs.get("context", [])
        reference_from_csv = ""
        attack_cases_text = []

        for doc in context_docs:
            # å¦‚æœ doc æ˜¯å­—å…¸ç±»å‹ï¼Œç›´æ¥æ£€æŸ¥ "metadata" é”®
            if isinstance(doc, dict) and "metadata" in doc:
                if "reference_text" in doc["metadata"]:
                    reference_from_csv = doc["metadata"]["reference_text"]
                    attack_cases_text.append(doc["content"])

        full_query = {
            "query": inputs.get("input", ""),
            "system_input": inputs.get("system_input", ""),
            "context": "\n\n".join(attack_cases_text),
            "reference_text": reference_from_csv
        }

        print("å®Œæ•´ä¼ å…¥å¤§æ¨¡å‹çš„æŸ¥è¯¢:", json.dumps(full_query, indent=2, ensure_ascii=False))
        return full_query


    # Step 5: æ„é€ æœ€ç»ˆ QA Chain
    question_answer_chain = (
        RunnablePassthrough.assign(context=history_aware_retriever) |
        RunnableLambda(format_inputs) |
        qa_prompt |
        llm
    )

    return create_retrieval_chain(history_aware_retriever, question_answer_chain)


class ResultSaver:
    def __init__(self, output_dir: str = "results"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def save_result(self, query: str, result: dict, source_file: str):
        print("å®Œæ•´ç»“æœç»“æ„:", json.dumps(result, indent=2, ensure_ascii=False))
        is_valid = (
            isinstance(result, dict) and
            result.get("answer") and
            not result["answer"].startswith(("æœªèƒ½è·å–", "APIè°ƒç”¨å¼‚å¸¸"))
        )

        if is_valid:
            filename = os.path.join(
                self.output_dir,
                f"result_{os.path.basename(source_file)}"
            )
            data = {
                "query": query,
                "answer": result["answer"],
                "source": source_file,
                "context": [
                    {
                        "content": doc.page_content[:200] + "...",
                        "source": doc.metadata.get("source_file", "unknown")
                    } for doc in result.get("context", [])
                ],
                "timestamp": datetime.now().isoformat()
            }
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        return False


# ============== ä¸»æ‰§è¡Œæµç¨‹ ==============
def load_system_input(file_name_without_ext):
    """
    åœ¨æŒ‡å®šæ ¹ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­æŸ¥æ‰¾åä¸º file_name_without_ext.txt.json çš„æ–‡ä»¶ï¼Œå¹¶è¿”å›å…¶ JSON å­—ç¬¦ä¸²å†…å®¹ã€‚
    å‚æ•°:
        file_name_without_ext: ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åï¼ˆå¦‚ 'system_input_path'ï¼‰
    è¿”å›:
        JSON å­—ç¬¦ä¸²ï¼ˆé ASCII è½¬ä¹‰ï¼‰ï¼Œæˆ–é”™è¯¯ä¿¡æ¯
    """
    base_dir = r"E:\code\tx-anomaly-predict\lsy\invocation_flow\output"
    target_file = f"{file_name_without_ext}.txt.json"

    for root, dirs, files in os.walk(base_dir):
        if target_file in files:
            full_path = os.path.join(root, target_file)
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    return json.dumps(json.load(f), ensure_ascii=False)
            except Exception as e:
                return f"é”™è¯¯: æ— æ³•è¯»å– JSON æ–‡ä»¶: {e}"

    return f"é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶ {target_file}ï¼ˆå·²åœ¨æ‰€æœ‰å­ç›®å½•ä¸­æŸ¥æ‰¾ï¼‰"


def format_to_html(text):
    # å…ˆå°† \n\n è½¬æ¢ä¸º <p> æ ‡ç­¾è¡¨ç¤ºæ®µè½
    paragraphs = text.split("\n\n")
    html_paragraphs = [f"<p>{p.replace('\n', '<br>')}</p>" for p in paragraphs]
    return "\n".join(html_paragraphs)



def run(system_input_path):
    embedding = JinaEmbedding()
    vector_store = load_or_create_vector_store(CONFIG["PERSIST_DIR"], embedding)
    ernie_ai = BaiduErnieAI()
    llm = ErnieLLMWrapper(ernie_ai)

    conversational_chain = create_conversational_chain(
        vector_store,
        llm,
        csv_file_path=CONFIG["CSV_PATH"]
    )

    query = "Please analyze the current input in the context of the preceding and following text to determine whether it pertains to attack contracts?You are the one who makes the decision and gives a clear yes or no answer.Please answer in chinese."
    reference_text = load_system_input(system_input_path)
    print(reference_text)

    result = conversational_chain.invoke({
        "input": query,
        "system_input": reference_text,
        "chat_history": [],
    })

    output_lines = []
    if isinstance(result, dict) and "answer" in result:
        output_lines.append(f"ç­”æ¡ˆ: {result['answer']}")
        if "context" in result:
            output_lines.append("\nå‚è€ƒæ–‡æ¡£:")
            for doc in result["context"]:
                output_lines.append(f"- {doc.metadata.get('source_file', 'æœªçŸ¥æ¥æº')}")
    else:
        output_lines.append(f"åŸå§‹ç»“æœ: {result}")

    return "\n".join(output_lines)
