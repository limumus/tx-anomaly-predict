import os
import json
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
import argparse
import glob
import requests
from langchain_core.messages import AIMessage
import re

# ============== å¯¼å…¥è¯„ä¼°ç±» ==============
# å‡è®¾ test_evaluate.py åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œæˆ–è€…æ‚¨éœ€è¦è°ƒæ•´å¯¼å…¥è·¯å¾„
try:
    from test_evaluate import ContractAnalyzerEvaluator
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œæˆ‘ä»¬å°†å†…è”å®šä¹‰å…³é”®å‡½æ•°
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥ test_evaluate.pyï¼Œä½¿ç”¨å†…è”è¯„ä¼°å‡½æ•°")

# ============== ç™¾åº¦æ–‡å¿ƒERNIEé…ç½® ==============
ERNIE_CONFIG = {

    # æµ‹è¯•é…ç½®
    "OUTPUT_FOLDER": r"G:\tx-anomaly-predict\lsy\invocation_flow\output",
    "RESULT_FOLDER": "./test_result/rag",
    "BATCH_SIZE": 20,
    "REQUEST_DELAY": 2,
}

# ============== ç™¾åº¦æ–‡å¿ƒERNIEæ¨¡å‹å°è£… ==============
class BaiduErnieAI:
    def __init__(self):
        self.access_key = ERNIE_CONFIG["BAIDU_ACCESS_KEY"]
        self.secret_key = ERNIE_CONFIG["BAIDU_SECRET_KEY"]
        self.api_url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie-speed-128k"

    def get_access_token(self):
        url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={self.access_key}&client_secret={self.secret_key}"
        try:
            response = requests.post(url, headers={'Content-Type': 'application/json'}, timeout=10)
            response.raise_for_status()
            return response.json().get("access_token")
        except Exception as e:
            print(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {str(e)}")
            return None

    def generate_response(self, messages: List[Dict[str, str]]) -> str:
        try:
            access_token = self.get_access_token()
            if not access_token:
                return "æ— æ³•è·å–è®¿é—®ä»¤ç‰Œ"
                
            url = f"{self.api_url}?access_token={access_token}"
            payload = json.dumps({"messages": messages})
            
            response = requests.post(url,
                                    headers={'Content-Type': 'application/json'},
                                    data=payload,
                                    timeout=30)
            response.raise_for_status()
            response_data = response.json()

            if "error_code" in response_data:
                return f"APIé”™è¯¯: {response_data.get('error_msg')}"
            return response_data.get("result", "æœªèƒ½è·å–å›ç­”")

        except requests.exceptions.Timeout:
            return "APIè¯·æ±‚è¶…æ—¶"
        except Exception as e:
            return f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}"

# ============== ç›´æ¥æ¨¡å‹è°ƒç”¨ç±» ==============
class DirectErnieClient:
    
    def __init__(self):
        self.ernie_ai = BaiduErnieAI()
    
    def analyze_transaction(self, transaction_data: str, query: str) -> str:
        """ç›´æ¥åˆ†æäº¤æ˜“æ•°æ®"""
        try:
            messages = [
                {
                    "role": "user",
                    "content": f"""You are an expert in smart contract attack detection. Evaluate whether the current transaction is malicious, using the following inputs:

Question: {query}

Current transaction data:
{transaction_data[:3000]}

Key Analysis Focus:
- Your task is to critically evaluate the transaction data
- Focus on:
  - Logical function call flow
  - Inter-contract calls
  - Abnormal fund transfers
- Ignore function names like `testExploit`; focus solely on execution logic.

Strict Answer Rules:
- You must begin your answer with one of: `Attack` or `Benign`.
- Follow this structured format:

[Attack | Benign]

1. Behavior Summary:
- Describe the transaction's overall behavior, including contract interactions and fund movements.

2. Call Sequence Analysis:
- Analyze the function call sequence and highlight any abnormal or suspicious patterns.

3. Malicious Indicators:
- Identify specific behaviors that indicate an attack.

- Limit your answer to 200 words.
"""
                }
            ]
            
            response = self.ernie_ai.generate_response(messages)
            return response
            
        except Exception as e:
            return f"ERNIE API Error: {str(e)}"

# ============== æ–‡ä»¶å¤„ç†å‡½æ•° ==============
def discover_test_files(output_folder: str) -> List[str]:
    """å‘ç°æµ‹è¯•æ–‡ä»¶"""
    pattern = os.path.join(output_folder, "**", "*_exp.sol", "*.txt.json")
    return glob.glob(pattern, recursive=True)

def load_transaction_data(file_path: str) -> str:
    """åŠ è½½äº¤æ˜“æ•°æ®"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return json.dumps(data, ensure_ascii=False)
    except Exception as e:
        print(f"Error loading file {file_path}: {e}")
        return ""

# ============== è¯„ä¼°å‡½æ•° - ä½¿ç”¨ test_evaluate.py ä¸­çš„é€»è¾‘ ==============
def extract_label(response: str) -> str:
    """ä»å“åº”ä¸­æå–æ ‡ç­¾ - ä½¿ç”¨ test_evaluate.py ä¸­çš„é€»è¾‘"""
    # å¤„ç†AIMessageå¯¹è±¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if isinstance(response, AIMessage):
        response_content = response.content
    elif isinstance(response, dict) and "answer" in response:
        # ä»å­—å…¸ä¸­æå–answerå­—æ®µï¼Œå®ƒå¯èƒ½æ˜¯AIMessageå¯¹è±¡
        answer = response["answer"]
        if isinstance(answer, AIMessage):
            response_content = answer.content
        else:
            response_content = str(answer)
    elif isinstance(response, str):
        response_content = response
    else:
        print(f"è­¦å‘Š: æœªçŸ¥çš„å“åº”ç±»å‹: {type(response)}")
        response_content = str(response)
    
    # ä»å†…å®¹ä¸­æå–æ ‡ç­¾ - æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼
    match = re.search(r'^\[?(Attack|Benign)\]?', response_content, re.IGNORECASE)
    if match:
        return match.group(1).capitalize()
    
    # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ ‡ç­¾æ ‡è®°ï¼Œå°è¯•åœ¨å†…å®¹ä¸­æŸ¥æ‰¾
    if re.search(r'\bAttack\b', response_content, re.IGNORECASE):
        return "Attack"
    elif re.search(r'\bBenign\b', response_content, re.IGNORECASE):
        return "Benign"
    
    return "Unknown"

def get_expected_label(file_path: str) -> str:
    """æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šé¢„æœŸæ ‡ç­¾ - ä½¿ç”¨ test_evaluate.py ä¸­çš„é€»è¾‘"""
    # å¦‚æœæ–‡ä»¶åœ¨ *_exp.sol æ–‡ä»¶å¤¹ä¸­ï¼Œåˆ™é¢„æœŸä¸ºAttack
    if "_exp.sol" in file_path:
        return "Attack"
    return "Attack"  # é»˜è®¤å‡è®¾ä¸ºAttack

def evaluate_response(response: str, file_path: str) -> Dict[str, Any]:
    """è¯„ä¼°æ¨¡å‹å“åº” - ä½¿ç”¨ test_evaluate.py ä¸­çš„é€»è¾‘"""
    predicted_label = extract_label(response)
    expected_label = get_expected_label(file_path)
    is_correct = predicted_label.lower() == expected_label.lower()
    
    return {
        "predicted_label": predicted_label,
        "expected_label": expected_label,
        "is_correct": is_correct,
        "response": response[:500] + "..." if len(response) > 500 else response,
        "has_required_format": bool(re.search(r'^\[?(Attack|Benign)\]?', response, re.IGNORECASE))
    }

# ============== æ‰¹å¤„ç†æ ¸å¿ƒå‡½æ•° ==============
def process_batch(files: List[str], batch_number: int, client: DirectErnieClient) -> List[Dict[str, Any]]:
    """å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡ä»¶"""
    batch_results = []
    
    for i, file_path in enumerate(files):
        try:
            print(f"  [{i+1}/{len(files)}] Processing: {os.path.basename(file_path)}")
            
            # åŠ è½½äº¤æ˜“æ•°æ®
            transaction_data = load_transaction_data(file_path)
            if not transaction_data:
                continue
            
            # å‡†å¤‡æŸ¥è¯¢
            query = "Please analyze this transaction to determine if it's an attack or benign contract behavior."
    
            # è°ƒç”¨æ¨¡å‹
            start_time = time.time()
            response = client.analyze_transaction(transaction_data, query)
            processing_time = time.time() - start_time
            
            # è¯„ä¼°ç»“æœ - ä½¿ç”¨æ”¹è¿›çš„è¯„ä¼°å‡½æ•°
            evaluation = evaluate_response(response, file_path)
            evaluation.update({
                "file_path": file_path,
                "file_name": os.path.basename(file_path),
                "folder_name": os.path.basename(os.path.dirname(file_path)),
                "processing_time": round(processing_time, 2),
                "batch_number": batch_number,
                "timestamp": datetime.now().isoformat(),
                "test_type": "attack"  # æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯æ”»å‡»æ ·æœ¬
            })
            
            batch_results.append(evaluation)
            
            print(f"    â†’ Prediction: {evaluation['predicted_label']}, Expected: {evaluation['expected_label']}, Time: {processing_time:.2f}s, Correct: {evaluation['is_correct']}")
            
            # è¯·æ±‚é—´éš”
            if i < len(files) - 1:
                time.sleep(ERNIE_CONFIG["REQUEST_DELAY"])
                
        except Exception as e:
            print(f"    â†’ Error: {str(e)}")
            error_result = {
                "file_path": file_path,
                "file_name": os.path.basename(file_path),
                "error": str(e),
                "batch_number": batch_number,
                "timestamp": datetime.now().isoformat()
            }
            batch_results.append(error_result)
            time.sleep(ERNIE_CONFIG["REQUEST_DELAY"] * 2)
    
    return batch_results

def run_direct_analysis(max_files: int = 0) -> Dict[str, Any]:
    """è¿è¡Œç›´æ¥æ¨¡å‹åˆ†æ"""
    # å‘ç°æ–‡ä»¶
    all_files = discover_test_files(ERNIE_CONFIG["OUTPUT_FOLDER"])
    if max_files > 0:
        all_files = all_files[:max_files]
    
    print(f"Found {len(all_files)} files for analysis")
    print(f"Batch size: {ERNIE_CONFIG['BATCH_SIZE']}")
    print("=" * 60)
    
    client = DirectErnieClient()
    all_results = []
    total_batches = (len(all_files) + ERNIE_CONFIG["BATCH_SIZE"] - 1) // ERNIE_CONFIG["BATCH_SIZE"]
    
    for batch_idx in range(total_batches):
        batch_start = batch_idx * ERNIE_CONFIG["BATCH_SIZE"]
        batch_end = min(batch_start + ERNIE_CONFIG["BATCH_SIZE"], len(all_files))
        batch_files = all_files[batch_start:batch_end]
        
        print(f"\nğŸ“¦ Batch {batch_idx + 1}/{total_batches}: Files {batch_start}-{batch_end-1}")
        print("-" * 50)
        
        # å¤„ç†å½“å‰æ‰¹æ¬¡
        batch_results = process_batch(batch_files, batch_idx + 1, client)
        all_results.extend(batch_results)
        
        # ä¿å­˜æ‰¹æ¬¡ç»“æœ
        save_batch_results(batch_results, batch_idx + 1)
        
        # æ‰¹æ¬¡é—´å»¶è¿Ÿ
        if batch_idx < total_batches - 1:
            delay = 30
            print(f"\nâ° Waiting {delay}s before next batch...")
            time.sleep(delay)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    return generate_final_report(all_results)

# ============== ç»“æœä¿å­˜å‡½æ•° ==============
def save_batch_results(results: List[Dict[str, Any]], batch_number: int):
    """ä¿å­˜æ‰¹æ¬¡ç»“æœ"""
    os.makedirs(ERNIE_CONFIG["RESULT_FOLDER"], exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"batch_{batch_number:03d}_{timestamp}.json"
    filepath = os.path.join(ERNIE_CONFIG["RESULT_FOLDER"], filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump({
            "batch_info": {
                "batch_number": batch_number,
                "total_files": len(results),
                "processing_date": timestamp,
                "model": "ernie-speed-128k"
            },
            "results": results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ Batch results saved to: {filename}")

def calculate_detailed_metrics(results: List[Dict[str, Any]]) -> Dict[str, float]:
    """è®¡ç®—è¯¦ç»†çš„è¯„ä¼°æŒ‡æ ‡ - ä½¿ç”¨ test_evaluate.py ä¸­çš„é€»è¾‘"""
    # åˆå§‹åŒ–è®¡æ•°å™¨
    tp_attack = 0  # çœŸæ­£ä¾‹ï¼šé¢„æµ‹ä¸ºAttackä¸”ç¡®å®ä¸ºAttack
    fp_attack = 0  # å‡æ­£ä¾‹ï¼šé¢„æµ‹ä¸ºAttackä½†å®é™…ä¸ºBenign  
    fn_attack = 0  # å‡åä¾‹ï¼šé¢„æµ‹ä¸ºBenignä½†å®é™…ä¸ºAttack
    tn_benign = 0  # çœŸåä¾‹ï¼šé¢„æµ‹ä¸ºBenignä¸”ç¡®å®ä¸ºBenign
    
    metrics = {
        "precision_attack": 0,
        "recall_attack": 0,
        "f1_score_attack": 0,
        "precision_benign": 0,
        "recall_benign": 0,
        "f1_score_benign": 0
    }
    
    for result in results:
        if "error" in result:
            continue
            
        if result["test_type"] == "attack":
            if result["predicted_label"].lower() == "attack":
                tp_attack += 1
            else:
                fn_attack += 1
        else:  # benign
            if result["predicted_label"].lower() == "benign":
                tn_benign += 1
            else:
                fp_attack += 1
    
    # è®¡ç®—Attackç±»çš„æŒ‡æ ‡
    if tp_attack + fp_attack > 0:
        metrics["precision_attack"] = tp_attack / (tp_attack + fp_attack)
    if tp_attack + fn_attack > 0:
        metrics["recall_attack"] = tp_attack / (tp_attack + fn_attack)
    if metrics["precision_attack"] > 0 and metrics["recall_attack"] > 0:
        metrics["f1_score_attack"] = (2 * metrics["precision_attack"] * metrics["recall_attack"] / 
                                    (metrics["precision_attack"] + metrics["recall_attack"]))
    
    return metrics

def generate_final_report(all_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    # è¿‡æ»¤å‡ºæœ‰æ•ˆç»“æœï¼ˆéé”™è¯¯ç»“æœï¼‰
    valid_results = [r for r in all_results if "error" not in r]
    error_results = [r for r in all_results if "error" in r]
    
    # è®¡ç®—æŒ‡æ ‡
    total_tests = len(valid_results)
    correct_predictions = sum(1 for r in valid_results if r.get("is_correct", False))
    accuracy = correct_predictions / total_tests if total_tests > 0 else 0
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    detailed_metrics = calculate_detailed_metrics(valid_results)
    
    # æ ‡ç­¾åˆ†å¸ƒ
    label_counts = {}
    for result in valid_results:
        label = result.get("predicted_label", "Unknown")
        label_counts[label] = label_counts.get(label, 0) + 1
    
    report = {
        "model": "ernie-speed-128k",
        "test_date": datetime.now().isoformat(),
        "metrics": {
            "total_files_processed": len(all_results),
            "valid_results": total_tests,
            "error_results": len(error_results),
            "correct_predictions": correct_predictions,
            "accuracy": accuracy,
            "average_processing_time": sum(r.get("processing_time", 0) for r in valid_results) / total_tests if total_tests > 0 else 0,
            **detailed_metrics
        },
        "label_distribution": label_counts,
        "summary": f"ERNIE direct analysis completed with {accuracy:.2%} accuracy"
    }
    
    # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
    os.makedirs(ERNIE_CONFIG["RESULT_FOLDER"], exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = os.path.join(ERNIE_CONFIG["RESULT_FOLDER"], f"final_report_{timestamp}.json")
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    return report

def print_summary(report: Dict[str, Any]):
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print(f"\n{'='*60}")
    print("ğŸ¯ ERNIE DIRECT ANALYSIS SUMMARY")
    print(f"{'='*60}")
    print(f"Model: {report['model']}")
    print(f"Date: {report['test_date']}")
    print(f"Total files processed: {report['metrics']['total_files_processed']}")
    print(f"Valid results: {report['metrics']['valid_results']}")
    print(f"Error results: {report['metrics']['error_results']}")
    print(f"Correct predictions: {report['metrics']['correct_predictions']}")
    print(f"Accuracy: {report['metrics']['accuracy']:.2%}")
    print(f"Avg processing time: {report['metrics']['average_processing_time']:.2f}s")
    
    # æ‰“å°è¯¦ç»†æŒ‡æ ‡
    print(f"\nğŸ“Š Detailed Metrics:")
    print(f"Attack Precision: {report['metrics']['precision_attack']:.2%}")
    print(f"Attack Recall: {report['metrics']['recall_attack']:.2%}")
    print(f"Attack F1 Score: {report['metrics']['f1_score_attack']:.2%}")
    
    print(f"\nğŸ“Š Label distribution:")
    for label, count in report['label_distribution'].items():
        print(f"  {label}: {count}")

# ============== ç¯å¢ƒæ£€æŸ¥å‡½æ•° ==============
def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    if ERNIE_CONFIG["BAIDU_ACCESS_KEY"] != "æ‚¨çš„ç™¾åº¦Access Key" and ERNIE_CONFIG["BAIDU_SECRET_KEY"] != "æ‚¨çš„ç™¾åº¦Secret Key":
        print("âœ… ç™¾åº¦æ–‡å¿ƒERNIE APIå¯†é’¥å·²é…ç½®")
        return True
    else:
        print("âŒ è¯·é…ç½®ç™¾åº¦æ–‡å¿ƒERNIE APIå¯†é’¥")
        return False

# ============== ä¸»å‡½æ•° ==============
def main():
    parser = argparse.ArgumentParser(description='ç™¾åº¦æ–‡å¿ƒERNIEç›´æ¥æµ‹è¯•å·¥å…·')
    parser.add_argument('--max_files', type=int, default=0,
                       help='æœ€å¤§å¤„ç†æ–‡ä»¶æ•°é‡ï¼ˆ0è¡¨ç¤ºæ‰€æœ‰æ–‡ä»¶ï¼‰')
    parser.add_argument('--batch_size', type=int, default=None,
                       help='æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°é‡')
    parser.add_argument('--delay', type=int, default=None,
                       help='è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰')
    
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    if args.batch_size:
        ERNIE_CONFIG["BATCH_SIZE"] = args.batch_size
    if args.delay:
        ERNIE_CONFIG["REQUEST_DELAY"] = args.delay
    
    # æ£€æŸ¥é…ç½®
    if not check_environment():
        return
    
    print("ğŸš€ å¼€å§‹ç™¾åº¦æ–‡å¿ƒERNIEç›´æ¥åˆ†æ")
    print("ğŸ“ æ— RAG - ç›´æ¥æ¨¡å‹æŸ¥è¯¢")
    print("=" * 60)
    
    # è¿è¡Œåˆ†æ
    report = run_direct_analysis(args.max_files)
    
    # æ‰“å°æ‘˜è¦
    print_summary(report)
    
    print(f"\nâœ… åˆ†æå®Œæˆ! ç»“æœä¿å­˜åœ¨: {ERNIE_CONFIG['RESULT_FOLDER']}")

if __name__ == "__main__":
    main()